{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML Final\n",
    "====                            \n",
    "106061121 莊裕嵐 106061140 許暐彤\n",
    "* 這個project中，我們希望能藉由input當地（如：日本東京）各項天氣資料（如：平均溫度、平均降水量、日照時間，及平均濕度等），來判定該年櫻花開花時間與時長。\n",
    "* 我們假設開花時機與短期天氣資訊有關，而花期時長則與長期天氣資訊相關，並由此分成2個model來訓練。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpKytGhYb2nL"
   },
   "source": [
    "## Implementation 1：開花時機\n",
    "* 先手動將日本各地、各年天氣相關數據從日本氣象廳網站（http://www.data.jma.go.jp/obd/stats/etrn/index.php ）上下載下來，再做初步的data preprocessing，如：刪除無關資料、填補空缺（用平均值、0等填補）等。手動將櫻花開花日（https://www.data.jma.go.jp/sakura/data/sakura003_06.html ）與滿開日（https://www.data.jma.go.jp/sakura/data/sakura004_06.html ）當作label填至dataset中，並假設滿開的後半旬會是櫻吹雪（即花期結束）。\n",
    "* 考慮到時間間隔的密度與資料擷取的效率，我們選用時間間隔較短的半旬（約5天）天氣資料做訓練。分別做出能辨別當半旬是開花、開花中、滿開、謝花、還是非花期的classifier，以及能預測下半旬是否開花的model。\n",
    "* 我們選取全年的資料作為input，花期的時間佔整年的一小部分、相對短暫，也造成data分布不均勻。經實驗後發現resample、平衡classes間的差距後，達成的performance比較好。\n",
    "* 將data標準化後，用LDA降低維度。每次取最高可留下features數作為LDA的參數，辨別當半旬是開花、開花中、滿開、謝花、還是非花期的classifier用4，預測下半旬是否開花的model則用1。\n",
    "* 在模型的選擇上，辨別當半旬是開花、開花中、滿開、謝花、還是非花期的classifier使用SVM。用balance後的dataset訓練，正確率可以達到99.9%。預測下半旬是否開花的model則分別使用SVM、Ensemble Classifier，及Random Forest，最後發現SVM效率最好。兩個models都有用grid search找最佳參數。\n",
    "* 另外，預測開花時，希望model不要錯過任何可能開花的機會、要盡可能地猜中，判定performance上使用f1。最後達成的正確率約為99.5%。\n",
    "* 最後用pipeline簡化我們的程式。\n",
    "\n",
    "## Result\n",
    "以下參數由Discussion裡探討得出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1 & 1-2 : 辨別當半旬是開花、開花中、滿開、謝花、還是非花期的classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.999\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# read in data for classification\n",
    "path = \"data_tokyo.csv\"\n",
    "df = pd.read_csv(path, encoding='latin1')\n",
    "\n",
    "# put in data & turn y into num\n",
    "data = df.T\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(data.T)): # for all input data\n",
    "    # store all data into X & y\n",
    "    X.append(np.array(data[i][3:24]))\n",
    "    y.append(data[i][24])\n",
    "\n",
    "# balance data\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "X_upsampled, y_upsampled = resample(X[y==1],\n",
    "                                   y[y==1],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X[y==0], X_upsampled))\n",
    "y_bal = np.hstack((y[y==0], y_upsampled))\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X[y==2],\n",
    "                                   y[y==2],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X_bal, X_upsampled))\n",
    "y_bal = np.hstack((y_bal, y_upsampled))\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X[y==3],\n",
    "                                   y[y==3],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X_bal, X_upsampled))\n",
    "y_bal = np.hstack((y_bal, y_upsampled))\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X[y==4],\n",
    "                                   y[y==4],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X_bal, X_upsampled))\n",
    "y_bal = np.hstack((y_bal, y_upsampled))\n",
    "\n",
    "# split into 70% training & 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, \n",
    "        y_bal, test_size=0.3, random_state=1, stratify=y_bal)\n",
    "\n",
    "# standardize Xs & feature-extract Xs & train SVM model w/ best parameters\n",
    "# 'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'\n",
    "pipe_svm = make_pipeline(StandardScaler(),\n",
    "                         LDA(n_components=4),\n",
    "                         SVC(C=0.1, gamma=10.0, kernel='rbf', random_state=1))\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "print('Test accuracy: % .3f' % pipe_svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-3 & 1-4 & 1-5: 預測下半旬是否開花的model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HH56vtu_b2nO",
    "outputId": "76649f46-2b43-4c50-d252-3062c57a8fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.995\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# read in data for prediction\n",
    "path = \"data_tokyo_pre.csv\"\n",
    "df = pd.read_csv(path, encoding='latin1')\n",
    "\n",
    "# put data into X & y\n",
    "data = df.T\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(data.T)): # for all input data\n",
    "    # store all data into X & y\n",
    "    X.append(np.array(data[i][3:24]))\n",
    "    y.append(data[i][24])\n",
    "\n",
    "# balance data\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "X_upsampled, y_upsampled = resample(X[y==1],\n",
    "                                   y[y==1],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X[y==0], X_upsampled))\n",
    "y_bal = np.hstack((y[y==0], y_upsampled))\n",
    "\n",
    "# split into 70% training & 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, \n",
    "        y_bal, test_size=0.3, random_state=1, stratify=y_bal)\n",
    "\n",
    "# standardize Xs & feature-extract Xs & train SVM model w/ best parameters\n",
    "# 'C': 1000.0, 'gamma': 1000.0, 'kernel': 'rbf'\n",
    "pipe_svm = make_pipeline(StandardScaler(),\n",
    "                         LDA(n_components=1),\n",
    "                         SVC(C=1000.0, gamma=1000.0, kernel='rbf', random_state=1))\n",
    "pipe_svm.fit(X_train, y_train)\n",
    "print('Test accuracy: % .3f' % pipe_svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_gXN0P7b2nR"
   },
   "source": [
    "### Discussion\n",
    "\n",
    "利用Google Chrome擴充功能－－Table Capture，我們可以將日本各地、各年天氣相關數據從日本氣象廳網站（http://www.data.jma.go.jp/obd/stats/etrn/index.php ）上下載下來。再做初步的data preprocessing，如：刪除無關資料（如：海上氣壓、風向）、用平均值填補空缺等。其中，原資料中的\"--\"表示完全沒有，0表示不足1，0.0則是表示不足0.1。為了方便處理，上述3種表示方法皆用0取代。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label部分則是手動輸入櫻花開花日（https://www.data.jma.go.jp/sakura/data/sakura003_06.html ）與滿開日（https://www.data.jma.go.jp/sakura/data/sakura004_06.html ），並假設滿開的後半旬會是櫻吹雪（即花期結束）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1：用unbalanced dataset辨別當半旬是開花、開花中、滿開、謝花、還是非花期的classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "iG6LBmjeb2nS",
    "outputId": "cab31497-8c10-4ac4-8153-87c87031cd80"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>atm(hPa)</th>\n",
       "      <th>Rav(mm)</th>\n",
       "      <th>Rmax_day(mm)</th>\n",
       "      <th>Rmax_hr(mm)</th>\n",
       "      <th>Rmax_10min(mm)</th>\n",
       "      <th>Tav(¢J)</th>\n",
       "      <th>Tav_max(¢J)</th>\n",
       "      <th>...</th>\n",
       "      <th>sun (h)</th>\n",
       "      <th>sunshine (MJ/¢T)</th>\n",
       "      <th>snow(cm)</th>\n",
       "      <th>snow_max(cm)</th>\n",
       "      <th>snow_depth(cm)</th>\n",
       "      <th>cloud</th>\n",
       "      <th>snow_day</th>\n",
       "      <th>fog_day</th>\n",
       "      <th>thunder_day</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1 to  5</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>37.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>6 to 10</td>\n",
       "      <td>1011.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>11 to 15</td>\n",
       "      <td>1015.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>15.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>16 to 20</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>21 to 25</td>\n",
       "      <td>1012.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month       day  atm(hPa)  Rav(mm)  Rmax_day(mm)  Rmax_hr(mm)  \\\n",
       "0  2008      1   1 to  5    1009.2      0.0           0.0          0.0   \n",
       "1  2008      1   6 to 10    1011.4      0.0           0.0          0.0   \n",
       "2  2008      1  11 to 15    1015.4      6.0           6.0          2.0   \n",
       "3  2008      1  16 to 20    1020.2      0.0           0.0          0.0   \n",
       "4  2008      1  21 to 25    1012.9     10.5          10.5          2.0   \n",
       "\n",
       "   Rmax_10min(mm)  Tav(¢J)  Tav_max(¢J)  ...  sun (h)  sunshine (MJ/¢T)  \\\n",
       "0             0.0      6.2         10.7  ...     37.8              10.4   \n",
       "1             0.0      9.0         12.9  ...     30.0               8.4   \n",
       "2             0.5      6.1          9.1  ...     15.5               6.0   \n",
       "3             0.0      4.6          8.0  ...     26.5               9.3   \n",
       "4             0.5      4.1          6.9  ...     22.1               7.9   \n",
       "\n",
       "   snow(cm)  snow_max(cm)  snow_depth(cm)  cloud  snow_day  fog_day  \\\n",
       "0         0             0               0    1.6         0        0   \n",
       "1         0             0               0    3.8         0        0   \n",
       "2         0             0               0    7.4         0        0   \n",
       "3         0             0               0    8.0         2        0   \n",
       "4         0             0               0    6.7         1        0   \n",
       "\n",
       "   thunder_day  Label  \n",
       "0            0      0  \n",
       "1            0      0  \n",
       "2            0      0  \n",
       "3            0      0  \n",
       "4            0      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"data_tokyo.csv\"\n",
    "df = pd.read_csv(path, encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fnUeVa_fSDl"
   },
   "source": [
    "雖然讀取進來的input有亂數（主要在header的單位表示上），不過不影響我們features的部分。讀取日期與label以外的資料放入X，並把label放入y。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [1015.4 6.0 6.0 2.0 0.5 6.1 9.1 3.3 13.0 1.9 45 23 15.5 6.0 0 0 0 7.4 0 0\n",
      " 0]\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = df.T\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(data.T)):          # read total input data\n",
    "    # store all data into X & y\n",
    "    X.append(np.array(data[i][3:24])) # skip dates\n",
    "    y.append(data[i][24])             # label\n",
    "print(\"X:\", X[2])\n",
    "print(\"Label:\", y[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把所有data讀進來後，可以利用train_test_split分成training與testing data。應該要有936組samples，各21個features。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v0z5H9urgXd1",
    "outputId": "2bd2218e-893e-4862-b267-d4dc35a39d7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (655, 21) y_train shape: (655,)\n",
      "X_test shape: (281, 21) y_test shape: (281,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into 70% training & 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "        y, test_size=0.3, random_state=1, stratify=y)\n",
    "print(\"X_train shape:\", np.array(X_train).shape, \"y_train shape:\", np.array(y_train).shape)\n",
    "print(\"X_test shape:\", np.array(X_test).shape, \"y_test shape:\", np.array(y_test).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WwLtRP2zoIe"
   },
   "source": [
    "有了training與testing data，我們可以standardize它們。要注意testing data不能fit到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2v8PxDMGzpIT",
    "outputId": "b22f099f-d593-4772-9274-245105835f67"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# standardize Xs\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voahqbjniT6A"
   },
   "source": [
    "在降低features維度、降低系統計算量上，我選擇使用feature extraction的LDA。因為總共有5個classes（開花、開花中、滿開、謝花，以及非花期），使用LDA時最後留下最多只有4個components。我選擇盡可能留下features，因此給它4作為參數。降維度時要注意，X_test不能fit到。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1_t2b4yicBG",
    "outputId": "98aa5fb1-ae6c-4d57-fdd1-ccd53d6e5fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(655, 4)\n",
      "(281, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.12296719,   0.54125559,   0.15654731,   0.17750079],\n",
       "       [  0.54903313,   0.3137964 ,   0.31461766,   0.77591575],\n",
       "       [ -0.54030289,  -0.30826651,  -0.0462416 ,  -0.44857304],\n",
       "       [ -0.15668896,  -0.15003383,  -0.41663565,   0.51968292],\n",
       "       [  0.12206149,   0.35018218,   0.17608409,  -0.49511936],\n",
       "       [ -1.68942147, -11.38878524,   4.61696636, -11.01410342],\n",
       "       [ -1.55955899,   3.42817038,  -6.68941339,   5.16068574],\n",
       "       [  1.97474609,   7.28684348,  -1.67693406,   5.04956667],\n",
       "       [  2.36297383,  -1.06590885,   1.56030091,   0.76898327],\n",
       "       [ -1.94252937,   1.58325895,   2.16906202,   0.3473863 ],\n",
       "       [ -0.09266294,  -0.53786174,   1.32069104,   0.30820939],\n",
       "       [ -0.23253636,   0.1980671 ,  -1.0469985 ,   0.11423336],\n",
       "       [ -0.58696868,   0.06294866,   1.2137452 ,  -1.79470082],\n",
       "       [  1.16545231,   0.73936161,  -0.28307378,   1.04990111],\n",
       "       [  0.66836615,  -2.16722232,  -0.07760983,  -0.69109764],\n",
       "       [ -0.47362189,   2.1667814 ,   0.07134486,   0.69311035],\n",
       "       [ -0.24452824,  -0.2525127 ,   0.05512884,   0.10027261],\n",
       "       [  0.11859875,   0.39303406,   0.59239525,  -1.43174444],\n",
       "       [ -0.13993051,   0.4013478 ,  -0.01413316,   0.23669934],\n",
       "       [ -0.10833804,   0.03441236,  -0.11784468,  -0.06525519],\n",
       "       [  0.02340269,  -0.12251862,   0.23719159,  -0.53126162]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "lda = LDA(n_components=4)\n",
    "X_train_lda = lda.fit_transform(X_train_std, y_train)\n",
    "X_test_lda = lda.transform(X_test_std)\n",
    "print(X_train_lda.shape)\n",
    "print(X_test_lda.shape)\n",
    "lda.scalings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WRbh4uGJsrR"
   },
   "source": [
    "有了降過維度的input features，我們可以著手開始建辨識的model。我選擇使用SVM作為這次模型的基礎，並利用Grid Search，找到表現最佳的參數組合。Performance的判定上使用accuracy，並利用1/4的validation fold訓練出更好的model（因為其中一個class數量較少，無法使用0.1作為validation fold）。另外，為了有效地利用CPU，將n_jobs設為-1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要注意餵training X與testing X時，都要給降過維度的，即X_train_lda與X_test_lda。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkVusqY0zSNh",
    "outputId": "9243981c-5b92-44f8-f98e-c7ffc9c87ea5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:01:53.287061\n",
      "0.952678437827323\n",
      "{'C': 0.0001, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "\n",
    "# train SVM using Grid Search\n",
    "svm = SVC(random_state=1)\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'C': param_range,\n",
    "               'kernel':['linear']},\n",
    "              {'C': param_range,\n",
    "               'gamma': param_range,\n",
    "               'kernel': ['rbf']}]\n",
    "gs = GridSearchCV(estimator=svm,\n",
    "                 param_grid = param_grid,\n",
    "                 scoring='accuracy',\n",
    "                 refit=True,\n",
    "                 cv=4,\n",
    "                 n_jobs=-1)\n",
    "start=datetime.now()\n",
    "gs = gs.fit(X_train_lda, y_train)\n",
    "print('Training time:', datetime.now()-start)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_4bNu7fWJwxy"
   },
   "source": [
    "因為上面的refit設定為true，function會幫我們train好model。藉由以下程式碼可以得到tesing data的正確率，要注意X_test要給標準化，且經過feature extraction過的，即X_test_lda。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHtPW18PcHTT",
    "outputId": "db40d217-1840-45da-8c3c-b8d072991513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.950\n"
     ]
    }
   ],
   "source": [
    "clf = gs.best_estimator_\n",
    "print('Test accuracy: % .3f' % clf.score(X_test_lda, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcX22p54WI3e"
   },
   "source": [
    "可以看出使用SVM的正確率相當高。但因為大部分時候為沒開花的狀況，難以確保model不是全猜\"非花期\"，才達到如此高的正確率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2：用balanced dataset辨別當半旬是開花、開花中、滿開、謝花、還是非花期的classifier\n",
    "基於上述問題，嘗試balance input samples，並使用accuracy以外的F1-score來判定performance。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先印出各個class的數量，以了解data的分布。我們可以直接重複使用上面的X, y參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QWcWKKLLU9uo",
    "outputId": "e10c3099-2a95-4915-c370-12920d0a47b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y [891  13   6  13  13]\n"
     ]
    }
   ],
   "source": [
    "print('Labels counts in y', np.bincount(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到整個花期與非花期的比例相差甚大，又因為最少數量的6筆資料稱不上\"大\"，我決定upsample數量較少的class，最後得到5組各891個samples的data set。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y_bal [891 891]\n",
      "Labels counts in y_bal [891 891 891]\n",
      "Labels counts in y_bal [891 891 891 891]\n",
      "Labels counts in y_bal [891 891 891 891 891]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X[y==1],\n",
    "                                   y[y==1],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X[y==0], X_upsampled))\n",
    "y_bal = np.hstack((y[y==0], y_upsampled))\n",
    "print('Labels counts in y_bal', np.bincount(y_bal))\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X[y==2],\n",
    "                                   y[y==2],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X_bal, X_upsampled))\n",
    "y_bal = np.hstack((y_bal, y_upsampled))\n",
    "print('Labels counts in y_bal', np.bincount(y_bal))\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X[y==3],\n",
    "                                   y[y==3],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X_bal, X_upsampled))\n",
    "y_bal = np.hstack((y_bal, y_upsampled))\n",
    "print('Labels counts in y_bal', np.bincount(y_bal))\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X[y==4],\n",
    "                                   y[y==4],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X_bal, X_upsampled))\n",
    "y_bal = np.hstack((y_bal, y_upsampled))\n",
    "print('Labels counts in y_bal', np.bincount(y_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著重複1-1的步驟，分成training與testing set、做standardization，並用LDA降低input features維度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3118, 21) y_train shape: (3118,)\n",
      "X_test shape: (1337, 21) y_test shape: (1337,)\n",
      "(3118, 4)\n",
      "(1337, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02542139, -0.06898238, -0.19378434, -0.37750223],\n",
       "       [ 0.31647064, -0.34648617, -0.59609098,  0.32950184],\n",
       "       [-0.39683662,  0.34369301,  0.04200649, -0.51567967],\n",
       "       [-0.21174496,  0.32177308,  0.01803565,  0.93036271],\n",
       "       [ 0.21691474, -0.67009378,  0.15310779, -0.6953184 ],\n",
       "       [ 1.63578526,  5.29066516, -2.84906556, -1.48110681],\n",
       "       [-1.63201377, -0.69535893,  1.4559581 ,  1.76325764],\n",
       "       [-0.43095728, -4.33053157,  1.07357468,  2.66722099],\n",
       "       [ 0.43836529,  0.41995835,  0.58345177, -0.97779521],\n",
       "       [-1.33391132, -0.25891746, -0.11637478, -2.43659859],\n",
       "       [ 0.30986901, -0.14719654, -1.21518331, -0.93828615],\n",
       "       [-0.61685507, -0.53041519,  0.26342029,  0.91590111],\n",
       "       [-0.5836573 ,  0.81031838,  0.66629079,  0.46374783],\n",
       "       [ 1.51224886, -0.89183769, -1.32556393, -0.60018614],\n",
       "       [-0.6362824 ,  2.13825882, -0.03404653,  1.26177055],\n",
       "       [ 0.79089082, -1.96855827, -0.14277732, -1.12099397],\n",
       "       [-0.26615093, -0.03125408,  0.05070877, -0.10664724],\n",
       "       [ 0.61671611,  1.39162079,  0.27085248,  0.22519229],\n",
       "       [-0.26843187, -0.60153015,  0.09705655, -0.44456473],\n",
       "       [-0.05167944, -0.04454622,  0.02684431,  0.01871989],\n",
       "       [-0.0373016 ,  0.27918695,  0.78760401, -0.58800149]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into 70% training & 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, \n",
    "        y_bal, test_size=0.3, random_state=1, stratify=y_bal)\n",
    "print(\"X_train shape:\", np.array(X_train).shape, \"y_train shape:\", np.array(y_train).shape)\n",
    "print(\"X_test shape:\", np.array(X_test).shape, \"y_test shape:\", np.array(y_test).shape)\n",
    "\n",
    "# standardize Xs\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "lda = LDA(n_components=4)\n",
    "X_train_lda = lda.fit_transform(X_train_std, y_train)\n",
    "X_test_lda = lda.transform(X_test_std)\n",
    "print(X_train_lda.shape)\n",
    "print(X_test_lda.shape)\n",
    "lda.scalings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同1-1，我們繼續使用SVM作為這次模型的基礎，利用Grid Search，找到表現最佳的參數組合。Performance的判定上使用能計算所有true positives, false negatives及false positives數的f1_micro，並利用0.1的validation fold訓練出更好的model。另外，為了有效地利用CPU，將n_jobs設為-1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:05:07.737406\n",
      "1.0\n",
      "{'C': 0.1, 'gamma': 10.0, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# train SVM using Grid Search\n",
    "svm = SVC(random_state=1)\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'C': param_range,\n",
    "               'kernel':['linear']},\n",
    "              {'C': param_range,\n",
    "               'gamma': param_range,\n",
    "               'kernel': ['rbf']}]\n",
    "gs = GridSearchCV(estimator=svm,\n",
    "                 param_grid = param_grid,\n",
    "                 scoring='f1_micro',\n",
    "                 refit=True,\n",
    "                 cv=10,\n",
    "                 n_jobs=-1)\n",
    "start=datetime.now()\n",
    "gs = gs.fit(X_train_lda, y_train)\n",
    "print('Training time:', datetime.now()-start)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9992520568436799\n",
      "f1 score macro: 0.9992523364485981\n",
      "f1 score micro: 0.9992520568436799\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "y_pred = clf.predict(X_test_lda)\n",
    "print (\"accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print (\"f1 score macro:\",metrics.f1_score(y_test, y_pred, average='macro') )\n",
    "print (\"f1 score micro:\",metrics.f1_score(y_test, y_pred, average='micro') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IcHZ02asWxD6"
   },
   "source": [
    "雖然training time約為原本的2.5倍左右，balance後train出來的模型正確率更高了。不過這個模型並不能\"預測\"櫻花開花，需要給當\"半旬\"（約5天）的天氣資料，它才能給出\"當半旬\"是否開花。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3：用SVM預測下半旬是否開花\n",
    "改變原本dataset內容，假設櫻花開花只與前半旬天氣有關、且僅考慮開花時間點，不考慮什麼時候滿開，以此進行預測。如此一來，只要input當半旬天氣資料，便能\"預測\"下半旬是否開花。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新的dataset僅更改原本label，開花前半旬為1，其他為0。用與前兩部分相同方式讀取資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>atm(hPa)</th>\n",
       "      <th>Rav(mm)</th>\n",
       "      <th>Rmax_day(mm)</th>\n",
       "      <th>Rmax_hr(mm)</th>\n",
       "      <th>Rmax_10min(mm)</th>\n",
       "      <th>Tav(¢J)</th>\n",
       "      <th>Tav_max(¢J)</th>\n",
       "      <th>...</th>\n",
       "      <th>sun (h)</th>\n",
       "      <th>sunshine (MJ/¢T)</th>\n",
       "      <th>snow(cm)</th>\n",
       "      <th>snow_max(cm)</th>\n",
       "      <th>snow_depth(cm)</th>\n",
       "      <th>cloud</th>\n",
       "      <th>snow_day</th>\n",
       "      <th>fog_day</th>\n",
       "      <th>thunder_day</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1 to  5</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>...</td>\n",
       "      <td>37.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>6 to 10</td>\n",
       "      <td>1011.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>11 to 15</td>\n",
       "      <td>1015.4</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>15.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>16 to 20</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26.5</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>21 to 25</td>\n",
       "      <td>1012.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month       day  atm(hPa)  Rav(mm)  Rmax_day(mm)  Rmax_hr(mm)  \\\n",
       "0  2008      1   1 to  5    1009.2      0.0           0.0          0.0   \n",
       "1  2008      1   6 to 10    1011.4      0.0           0.0          0.0   \n",
       "2  2008      1  11 to 15    1015.4      6.0           6.0          2.0   \n",
       "3  2008      1  16 to 20    1020.2      0.0           0.0          0.0   \n",
       "4  2008      1  21 to 25    1012.9     10.5          10.5          2.0   \n",
       "\n",
       "   Rmax_10min(mm)  Tav(¢J)  Tav_max(¢J)  ...  sun (h)  sunshine (MJ/¢T)  \\\n",
       "0             0.0      6.2         10.7  ...     37.8              10.4   \n",
       "1             0.0      9.0         12.9  ...     30.0               8.4   \n",
       "2             0.5      6.1          9.1  ...     15.5               6.0   \n",
       "3             0.0      4.6          8.0  ...     26.5               9.3   \n",
       "4             0.5      4.1          6.9  ...     22.1               7.9   \n",
       "\n",
       "   snow(cm)  snow_max(cm)  snow_depth(cm)  cloud  snow_day  fog_day  \\\n",
       "0         0             0               0    1.6         0        0   \n",
       "1         0             0               0    3.8         0        0   \n",
       "2         0             0               0    7.4         0        0   \n",
       "3         0             0               0    8.0         2        0   \n",
       "4         0             0               0    6.7         1        0   \n",
       "\n",
       "   thunder_day  Label  \n",
       "0            0      0  \n",
       "1            0      0  \n",
       "2            0      0  \n",
       "3            0      0  \n",
       "4            0      0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"data_tokyo_pre.csv\"\n",
    "\n",
    "df = pd.read_csv(path, encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把讀取進來的資料分別放進X, y。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [1015.4 6.0 6.0 2.0 0.5 6.1 9.1 3.3 13.0 1.9 45 23 15.5 6.0 0 0 0 7.4 0 0\n",
      " 0]\n",
      "Label: 0\n",
      "Labels counts in y [923  13]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = df.T\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(data.T)): # for all input data\n",
    "    # store all data into X & y\n",
    "    X.append(np.array(data[i][3:24]))\n",
    "    y.append(data[i][24])\n",
    "print(\"X:\", X[2])\n",
    "print(\"Label:\", y[2])\n",
    "print('Labels counts in y', np.bincount(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到label=1的數量相對稀少很多，而這也是合理的，因為櫻花一年只會開一次。為了train出更好的model，我們先upsample、平衡兩個classes間的差距。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y_bal [923 923]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "X_upsampled, y_upsampled = resample(X[y==1],\n",
    "                                   y[y==1],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X[y==0], X_upsampled))\n",
    "y_bal = np.hstack((y[y==0], y_upsampled))\n",
    "print('Labels counts in y_bal', np.bincount(y_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同樣將balanced dataset分成training與testing set、做standardization，並用LDA降低input features維度。因為總共只有2種classes，LDA最多只能留下1個feature。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1292, 21) y_train shape: (1292,)\n",
      "X_test shape: (554, 21) y_test shape: (554,)\n",
      "(1292, 1)\n",
      "(554, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.31414079e-02],\n",
       "       [ 1.25319653e-01],\n",
       "       [-2.16563968e-01],\n",
       "       [ 1.70098773e-01],\n",
       "       [-1.93857443e-01],\n",
       "       [ 2.60421348e+00],\n",
       "       [-1.93333859e+00],\n",
       "       [-2.83079594e+00],\n",
       "       [ 1.12271026e+00],\n",
       "       [-5.00371809e-01],\n",
       "       [ 2.66694394e-01],\n",
       "       [ 8.15765736e-03],\n",
       "       [-9.64220152e-01],\n",
       "       [ 1.23778639e+00],\n",
       "       [ 3.79199332e-01],\n",
       "       [-2.99238714e-03],\n",
       "       [-3.40257071e-01],\n",
       "       [ 1.43701291e-02],\n",
       "       [-5.08542075e-01],\n",
       "       [ 1.38291015e-03],\n",
       "       [-7.80961031e-02]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# split into 70% training & 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, \n",
    "        y_bal, test_size=0.3, random_state=1, stratify=y_bal)\n",
    "print(\"X_train shape:\", np.array(X_train).shape, \"y_train shape:\", np.array(y_train).shape)\n",
    "print(\"X_test shape:\", np.array(X_test).shape, \"y_test shape:\", np.array(y_test).shape)\n",
    "\n",
    "# standardize Xs\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "lda = LDA(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train_std, y_train)\n",
    "X_test_lda = lda.transform(X_test_std)\n",
    "print(X_train_lda.shape)\n",
    "print(X_test_lda.shape)\n",
    "lda.scalings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "繼續使用SVM，並利用Grid Search找到表現最佳的參數組合。希望要盡可能地答對\"開花時間\"，Performance的判定上使用f1，並利用0.1的validation fold訓練出更好的model。另外，為了有效地利用CPU，將n_jobs設為-1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:24.743289\n",
      "0.9900870161758537\n",
      "{'C': 1000.0, 'gamma': 1000.0, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# train SVM using Grid Search\n",
    "svm = SVC(random_state=1)\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'C': param_range,\n",
    "               'kernel':['linear']},\n",
    "              {'C': param_range,\n",
    "               'gamma': param_range,\n",
    "               'kernel': ['rbf']}]\n",
    "gs = GridSearchCV(estimator=svm,\n",
    "                 param_grid = param_grid,\n",
    "                 scoring='f1',\n",
    "                 refit=True,\n",
    "                 cv=10,\n",
    "                 n_jobs=-1)\n",
    "start=datetime.now()\n",
    "gs = gs.fit(X_train_lda, y_train)\n",
    "print('Training time:', datetime.now()-start)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為features維度下降，再加上總sample數也相對少，與1-2相比training time大幅下降。雖然performance不如1-2，但這個model才能真正地\"預測\"開花。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9945848375451264\n",
      "f1 score: 0.9946140035906643\n",
      "f1 score macro: 0.9945846787463304\n",
      "f1 score micro: 0.9945848375451264\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "clf = gs.best_estimator_\n",
    "\n",
    "y_pred = clf.predict(X_test_lda)\n",
    "print (\"accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print (\"f1 score:\",metrics.f1_score(y_test, y_pred) )\n",
    "print (\"f1 score macro:\",metrics.f1_score(y_test, y_pred, average='macro') )\n",
    "print (\"f1 score micro:\",metrics.f1_score(y_test, y_pred, average='micro') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到不管用哪一種方式判定performance，大約都有99.5%的正確率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1de5aa608e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf, X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從confusion matrix可以看出來，雖然這個model會有誤判的時候，但卻不會錯過任何\"下半旬\"開花的可能性，且預測會開花、而真的有開花的機率挺高的，約為98.9%（=277/(277+3)）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-4：用其他classifier預測下半旬是否開花\n",
    "用上述相同dataset，嘗試使用其他ML models，並比較各自的performance。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87 (+/- 0.02) [Logistic Regression]\n",
      "Accuracy: 0.99 (+/- 0.01) [Random Forest]\n",
      "Accuracy: 0.97 (+/- 0.01) [K-Neighbors]\n",
      "Accuracy: 0.85 (+/- 0.03) [SVM]\n",
      "Accuracy: 0.98 (+/- 0.01) [Ensemble]\n",
      "Test accuracy:  0.984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# train model\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = SVC(probability=True)\n",
    "\n",
    "# larger weight for classifier w/ higher accuracy\n",
    "eclf = VotingClassifier(\n",
    "     estimators=[('lr', clf1), ('rf', clf2), ('knn', clf3), ('svm', clf4)],\n",
    "     voting='soft', weights=[1,4,4,1])\n",
    "\n",
    "# print out each & overall accuracies\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, eclf], ['Logistic Regression', 'Random Forest', 'K-Neighbors', 'SVM', 'Ensemble']):\n",
    "     scores = cross_val_score(clf, X_train_lda, y_train, scoring='f1', cv=5)\n",
    "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "\n",
    "# Predict on test set\n",
    "eclf = eclf.fit(X_train_lda, y_train)\n",
    "print('Test accuracy: % .3f' % eclf.score(X_test_lda, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到當所有classifier表現都不錯時，Ensemble Classifier並沒辦法提升太多performance。我們把training accuracy最高的Random Forest單獨拉出來測試。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9945848375451264\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "forest = forest.fit(X_train_lda, y_train)\n",
    "print('Test accuracy:' , forest.score(X_test_lda, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-5：探討Random Forest參數\n",
    "因為上述Random Forest表現與SVM差不多好，又符合我們想要\"預測\"花期的功能，看看是否能改用Random Forest model提升它的準確率，或降低訓練時間。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest有許多參數可以調整。我將criterion設為gini，將n_jobs設為-1、盡可能地利用CPU。而為了避免overfitting，我設最大深度為1，也就是features的總數。bootstrap則是設定採樣是否有放回，我採用的方法是bagging也就是採樣會放回的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators設定的是樹的總量。在其他參數固定的狀況下，我試了幾種不同值，以正確率100%為目標，選擇樹最少、表現最穩定的值以達到較佳的效率（避免過多計算）。Training與testing data直接使用上方的X_train_lda, y_train, X_test_lda, 及y_test。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when n =  1 : 0.8700361010830325\n",
      "Accuracy when n =  2 : 0.8700361010830325\n",
      "Accuracy when n =  3 : 0.8700361010830325\n",
      "Accuracy when n =  4 : 0.8700361010830325\n",
      "Accuracy when n =  5 : 0.8700361010830325\n",
      "Accuracy when n =  6 : 0.8700361010830325\n",
      "Accuracy when n =  7 : 0.8700361010830325\n",
      "Accuracy when n =  8 : 0.8700361010830325\n",
      "Accuracy when n =  9 : 0.8700361010830325\n",
      "Accuracy when n =  10 : 0.8700361010830325\n",
      "Accuracy when n =  11 : 0.8700361010830325\n",
      "Accuracy when n =  12 : 0.8700361010830325\n",
      "Accuracy when n =  13 : 0.8700361010830325\n",
      "Accuracy when n =  14 : 0.8700361010830325\n",
      "Accuracy when n =  15 : 0.8700361010830325\n",
      "Accuracy when n =  16 : 0.8700361010830325\n",
      "Accuracy when n =  17 : 0.8700361010830325\n",
      "Accuracy when n =  18 : 0.8700361010830325\n",
      "Accuracy when n =  19 : 0.8700361010830325\n",
      "Accuracy when n =  20 : 0.8700361010830325\n",
      "Accuracy when n =  21 : 0.8700361010830325\n",
      "Accuracy when n =  22 : 0.8700361010830325\n",
      "Accuracy when n =  23 : 0.8700361010830325\n",
      "Accuracy when n =  24 : 0.8700361010830325\n",
      "Accuracy when n =  25 : 0.8700361010830325\n",
      "Accuracy when n =  26 : 0.8700361010830325\n",
      "Accuracy when n =  27 : 0.8700361010830325\n",
      "Accuracy when n =  28 : 0.8700361010830325\n",
      "Accuracy when n =  29 : 0.8700361010830325\n",
      "Accuracy when n =  30 : 0.8700361010830325\n",
      "Accuracy when n =  31 : 0.8700361010830325\n",
      "Accuracy when n =  32 : 0.8700361010830325\n",
      "Accuracy when n =  33 : 0.8700361010830325\n",
      "Accuracy when n =  34 : 0.8700361010830325\n",
      "Accuracy when n =  35 : 0.8700361010830325\n",
      "Accuracy when n =  36 : 0.8700361010830325\n",
      "Accuracy when n =  37 : 0.8700361010830325\n",
      "Accuracy when n =  38 : 0.8700361010830325\n",
      "Accuracy when n =  39 : 0.8700361010830325\n",
      "Accuracy when n =  40 : 0.8700361010830325\n",
      "Accuracy when n =  41 : 0.8700361010830325\n",
      "Accuracy when n =  42 : 0.8700361010830325\n",
      "Accuracy when n =  43 : 0.8700361010830325\n",
      "Accuracy when n =  44 : 0.8700361010830325\n",
      "Accuracy when n =  45 : 0.8700361010830325\n",
      "Accuracy when n =  46 : 0.8700361010830325\n",
      "Accuracy when n =  47 : 0.8700361010830325\n",
      "Accuracy when n =  48 : 0.8700361010830325\n",
      "Accuracy when n =  49 : 0.8700361010830325\n",
      "Accuracy when n =  50 : 0.8700361010830325\n",
      "Accuracy when n =  51 : 0.8700361010830325\n",
      "Accuracy when n =  52 : 0.8700361010830325\n",
      "Accuracy when n =  53 : 0.8700361010830325\n",
      "Accuracy when n =  54 : 0.8700361010830325\n",
      "Accuracy when n =  55 : 0.8700361010830325\n",
      "Accuracy when n =  56 : 0.8700361010830325\n",
      "Accuracy when n =  57 : 0.8700361010830325\n",
      "Accuracy when n =  58 : 0.8700361010830325\n",
      "Accuracy when n =  59 : 0.8700361010830325\n",
      "Accuracy when n =  60 : 0.8700361010830325\n",
      "Accuracy when n =  61 : 0.8700361010830325\n",
      "Accuracy when n =  62 : 0.8700361010830325\n",
      "Accuracy when n =  63 : 0.8700361010830325\n",
      "Accuracy when n =  64 : 0.8700361010830325\n",
      "Accuracy when n =  65 : 0.8700361010830325\n",
      "Accuracy when n =  66 : 0.8700361010830325\n",
      "Accuracy when n =  67 : 0.8700361010830325\n",
      "Accuracy when n =  68 : 0.8700361010830325\n",
      "Accuracy when n =  69 : 0.8700361010830325\n",
      "Accuracy when n =  70 : 0.8700361010830325\n",
      "Accuracy when n =  71 : 0.8700361010830325\n",
      "Accuracy when n =  72 : 0.8700361010830325\n",
      "Accuracy when n =  73 : 0.8700361010830325\n",
      "Accuracy when n =  74 : 0.8700361010830325\n",
      "Accuracy when n =  75 : 0.8700361010830325\n",
      "Accuracy when n =  76 : 0.8700361010830325\n",
      "Accuracy when n =  77 : 0.8700361010830325\n",
      "Accuracy when n =  78 : 0.8700361010830325\n",
      "Accuracy when n =  79 : 0.8700361010830325\n",
      "Accuracy when n =  80 : 0.8700361010830325\n",
      "Accuracy when n =  81 : 0.8700361010830325\n",
      "Accuracy when n =  82 : 0.8700361010830325\n",
      "Accuracy when n =  83 : 0.8700361010830325\n",
      "Accuracy when n =  84 : 0.8700361010830325\n",
      "Accuracy when n =  85 : 0.8700361010830325\n",
      "Accuracy when n =  86 : 0.8700361010830325\n",
      "Accuracy when n =  87 : 0.8700361010830325\n",
      "Accuracy when n =  88 : 0.8700361010830325\n",
      "Accuracy when n =  89 : 0.8700361010830325\n",
      "Accuracy when n =  90 : 0.8700361010830325\n",
      "Accuracy when n =  91 : 0.8700361010830325\n",
      "Accuracy when n =  92 : 0.8700361010830325\n",
      "Accuracy when n =  93 : 0.8700361010830325\n",
      "Accuracy when n =  94 : 0.8700361010830325\n",
      "Accuracy when n =  95 : 0.8700361010830325\n",
      "Accuracy when n =  96 : 0.8700361010830325\n",
      "Accuracy when n =  97 : 0.8700361010830325\n",
      "Accuracy when n =  98 : 0.8700361010830325\n",
      "Accuracy when n =  99 : 0.8700361010830325\n",
      "Accuracy when n =  100 : 0.8700361010830325\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWzUlEQVR4nO3dfbRddX3n8feHBOQZtKQMEIagE3nQEdQ7VGhrUZwK9YFOKyNMHSu1ZaiolKlWrB2r41qzbK0zOqJSpIBaRgYBLdgZQSOKq7OKueHBEB5qDAoRLKHUZwUi3/lj77SHyy/JSbibk9z7fq111z374ez9/d2T7M/Z+3fOb6eqkCRpph0mXYAkadtkQEiSmgwISVKTASFJajIgJElNCyddwGzaZ599asmSJZMuQ5K2GytWrLi/qha1ls2pgFiyZAnT09OTLkOSthtJvrmxZV5ikiQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaBg2IJMcnuSPJ6iRnN5Y/Ocmnknw1yVeSPHPc50qShjVYQCRZAHwQOAE4HDglyeEzVvtD4KaqehbwauD9W/BcSdKAhjyDOApYXVVrquoh4BLgxBnrHA4sA6iq24ElSfYd87mSpAENGRAHAHePTK/t5426Gfg1gCRHAQcBi8d8Lv3zTksynWR63bp1s1S6JGnIgEhjXs2Yfjfw5CQ3AW8AbgTWj/ncbmbVeVU1VVVTixYtehzlSpJGLRxw22uBA0emFwP3jK5QVd8DTgVIEuDO/mfXzT1XkjSsIc8glgNLkxycZCfgZODK0RWS7N0vA/ht4Lo+NDb7XEnSsAY7g6iq9UleD1wNLAAuqKpVSU7vl58LHAZ8LMlPgVuB127quUPVKkl6rFQ1L+1vl6ampmp6enrSZUjSdiPJiqqaai3zm9SSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUtOgAZHk+CR3JFmd5OzG8r2SXJXk5iSrkpw6suysft4tST6RZOcha5UkPdpgAZFkAfBB4ATgcOCUJIfPWO0M4NaqOgI4Fnhvkp2SHAC8EZiqqmcCC4CTh6pVkvRYQ55BHAWsrqo1VfUQcAlw4ox1CtgjSYDdgQeA9f2yhcAuSRYCuwL3DFirJGmGIQPiAODukem1/bxR5wCH0R38VwJnVtUjVfUt4M+Au4B7ge9W1TUD1ipJmmHIgEhjXs2YfjFwE7A/cCRwTpI9kzyZ7mzj4H7Zbkle1dxJclqS6STT69atm63aJWneGzIg1gIHjkwv5rGXiU4FrqjOauBO4FDgRcCdVbWuqh4GrgCOae2kqs6rqqmqmlq0aNGsN0KS5qvNBkSSlybZmiBZDixNcnCSneg6ma+csc5dwHH9fvYFDgHW9POfl2TXvn/iOOC2rahBkrSVxjnwnwx8LcmfJjls3A1X1Xrg9cDVdAf3S6tqVZLTk5zer/Yu4JgkK4FlwFuq6v6quh64DLiBrm9iB+C8sVslSXrcUjWzW6CxUrIncArdJaECLgQ+UVXfH7a8LTM1NVXT09OTLkOSthtJVlTVVGvZWJeOqup7wOV0H1XdD/h3wA1J3jBrVUqStinj9EG8LMmngC8AOwJHVdUJwBHAmwauT5I0IQvHWOck4H9U1XWjM6vqR0l+a5iyJEmTNk5A/DHdl9UASLILsG9VfaOqlg1WmSRposbpg/gk8MjI9E/7eZKkOWycgFjYj6UEQP94p+FKkiRtC8YJiHVJXr5hIsmJwP3DlSRJ2haM0wdxOnBxknPoxle6G3j1oFVJkiZuswFRVV+nG/Zid7ov1m1TX46TJA1jnDMIkrwEeAawczc0ElTVfx2wLknShI3zRblzgVcCb6C7xHQScNDAdUmSJmycTupjqurVwD9W1TuBo3n0MN6SpDlonID4Sf/7R0n2Bx6mu5GPJGkOG6cP4qokewPvoRt+u4CPDFmUJGnyNhkQ/Y2CllXVd4DLk3wG2LmqvvtEFCdJmpxNXmKqqkeA945MP2g4SNL8MM4lpmuS/Dr9vaOHLmgS3nnVKm6953uTLkOStsrh++/JH7/sGbO+3XEC4j8DuwHrk/yE7qOuVVV7zno1kqRtxjjfpN7jiShkkoZIXkna3m02IJI8vzV/5g2EJElzyziXmN488nhn4ChgBfDCQSqSJG0TxrnE9LLR6SQHAn86WEWSpG3CON+knmkt8MzZLkSStG0Zpw/iA3TfnoYuUI4Ebh6wJknSNmCcPojpkcfrgU9U1d8MVI8kaRsxTkBcBvykqn4KkGRBkl2r6kfDliZJmqRx+iCWAbuMTO8CfH6YciRJ24pxAmLnqvrBhon+8a7DlSRJ2haMExA/TPKcDRNJngv8eLiSJEnbgnH6IH4P+GSSe/rp/ehuQSpJmsPG+aLc8iSHAofQDdR3e1U9PHhlkqSJ2uwlpiRnALtV1S1VtRLYPcnrhi9NkjRJ4/RB/E5/RzkAquofgd8ZrCJJ0jZhnIDYIUk2TCRZAOw0XEmSpG3BOJ3UVwOXJjmXbsiN04H/O2hVkqSJGycg3gKcBvwuXSf1jXSfZJIkzWGbvcRUVY8AfwusAaaA44DbBq5LkjRhGw2IJE9P8vYktwHnAHcDVNULquqccTae5PgkdyRZneTsxvK9klyV5OYkq5KcOrJs7ySXJbk9yW1Jjt7y5kmSttamLjHdDnwZeFlVrQZIcta4G+47sz8I/Fu6e0gsT3JlVd06stoZwK1V9bIki4A7klxcVQ8B7wc+W1WvSLITDu8hSU+oTV1i+nXg28C1ST6S5Di6PohxHQWsrqo1/QH/EuDEGesUsEf/KandgQeA9Un2BJ4P/AVAVT00+lFbSdLwNhoQVfWpqnolcCjwReAsYN8kH07yy2Ns+wD6y1K9tf28UecAhwH3ACuBM/s+j6cC64ALk9yY5Pwku7V2kuS0JNNJptetWzdGWZKkcYzTSf3Dqrq4ql4KLAZuAh7Tn9DQOtuoGdMv7re3P92d6s7pzx4WAs8BPlxVzwZ+uLF9VtV5VTVVVVOLFi0aoyxJ0ji26J7UVfVAVf15Vb1wjNXXAgeOTC+mO1MYdSpwRXVWA3fSnbGsBdZW1fX9epfRBYYk6QmyRQGxhZYDS5Mc3HcynwxcOWOdu+g+NkuSfekGBFxTVd8G7k5ySL/eccCtSJKeMON8UW6rVNX6JK+n+yb2AuCCqlqV5PR++bnAu4CLkqykuyT1lqq6v9/EG4CL+3BZQ3e2IUl6gqRqZrfA9mtqaqqmp6cnXYYkbTeSrKiqqdayIS8xSZK2YwaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkpkEDIsnxSe5IsjrJ2Y3leyW5KsnNSVYlOXXG8gVJbkzymSHrlCQ91mABkWQB8EHgBOBw4JQkh89Y7Qzg1qo6AjgWeG+SnUaWnwncNlSNkqSNG/IM4ihgdVWtqaqHgEuAE2esU8AeSQLsDjwArAdIshh4CXD+gDVKkjZiyIA4ALh7ZHptP2/UOcBhwD3ASuDMqnqkX/Y+4A+AR9iEJKclmU4yvW7dutmoW5LEsAGRxryaMf1i4CZgf+BI4JwkeyZ5KXBfVa3Y3E6q6ryqmqqqqUWLFj3OkiVJGwwZEGuBA0emF9OdKYw6FbiiOquBO4FDgZ8HXp7kG3SXpl6Y5C8HrFWSNMOQAbEcWJrk4L7j+WTgyhnr3AUcB5BkX+AQYE1VvbWqFlfVkv55X6iqVw1YqyRphoVDbbiq1id5PXA1sAC4oKpWJTm9X34u8C7goiQr6S5JvaWq7h+qJknS+FI1s1tg+zU1NVXT09OTLkOSthtJVlTVVGuZ36SWJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUlKqadA2zJsk64Jtb8JR9gPsHKmdbNR/bDPOz3fOxzTA/2/142nxQVS1qLZhTAbGlkkxX1dSk63gizcc2w/xs93xsM8zPdg/VZi8xSZKaDAhJUtN8D4jzJl3ABMzHNsP8bPd8bDPMz3YP0uZ53QchSdq4+X4GIUnaCANCktQ0LwMiyfFJ7kiyOsnZk65nKEkOTHJtktuSrEpyZj//KUk+l+Rr/e8nT7rW2ZZkQZIbk3ymn54Pbd47yWVJbu9f86PneruTnNX/274lySeS7DwX25zkgiT3JbllZN5G25nkrf3x7Y4kL97a/c67gEiyAPggcAJwOHBKksMnW9Vg1gO/X1WHAc8DzujbejawrKqWAsv66bnmTOC2ken50Ob3A5+tqkOBI+jaP2fbneQA4I3AVFU9E1gAnMzcbPNFwPEz5jXb2f8fPxl4Rv+cD/XHvS027wICOApYXVVrquoh4BLgxAnXNIiqureqbugff5/ugHEAXXs/2q/2UeBXJ1LgQJIsBl4CnD8ye663eU/g+cBfAFTVQ1X1HeZ4u4GFwC5JFgK7AvcwB9tcVdcBD8yYvbF2nghcUlUPVtWdwGq6494Wm48BcQBw98j02n7enJZkCfBs4Hpg36q6F7oQAX52gqUN4X3AHwCPjMyb621+KrAOuLC/tHZ+kt2Yw+2uqm8BfwbcBdwLfLeqrmEOt3mGjbVz1o5x8zEg0pg3pz/rm2R34HLg96rqe5OuZ0hJXgrcV1UrJl3LE2wh8Bzgw1X1bOCHzI1LKxvVX3M/ETgY2B/YLcmrJlvVNmHWjnHzMSDWAgeOTC+mOy2dk5LsSBcOF1fVFf3sv0+yX798P+C+SdU3gJ8HXp7kG3SXD1+Y5C+Z222G7t/12qq6vp++jC4w5nK7XwTcWVXrquph4ArgGOZ2m0dtrJ2zdoybjwGxHFia5OAkO9F15lw54ZoGkSR016Rvq6r/PrLoSuA3+8e/CfzVE13bUKrqrVW1uKqW0L22X6iqVzGH2wxQVd8G7k5ySD/rOOBW5na77wKel2TX/t/6cXT9bHO5zaM21s4rgZOTPCnJwcBS4CtbtYeqmnc/wK8Afwd8HXjbpOsZsJ2/QHdq+VXgpv7nV4CfofvUw9f630+ZdK0Dtf9Y4DP94znfZuBIYLp/vT8NPHmutxt4J3A7cAvwceBJc7HNwCfo+lkepjtDeO2m2gm8rT++3QGcsLX7dagNSVLTfLzEJEkagwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0JbJUklee/I9JuSvGOWtn1RklfMxrY2s5+T+mGxrx2Z96+T3NT/PJDkzv7x5weq4dlJzt/8mo97P69Jsv/I9PmzMYpxkiVJ/sPj3c7I9j4/F4bnnisMCG2tB4FfS7LPpAsZtYXDGr8WeF1VvWDDjKpaWVVHVtWRdN9IfXM//aKRfSyctYLhD4EPzOL2NuY1dOMVAVBVv11Vt87CdpcAWxQQm/n7fRx43eMpSLPHgNDWWk93o/SzZi6YeQaQ5Af972OTfCnJpUn+Lsm7k/xGkq8kWZnkaSObeVGSL/frvbR//oIk70myPMlXk/ynke1em+R/ASsb9ZzSb/+WJH/Sz3s73TfNz03yns01NskXk/y3JF8Czkzy3L4tK5JcPTImztOSfLaf/+Ukh/bzT+r3f3OS6/p5ewDPqqqb++l3pLsxzBeTrEnyxs3U9Kr+b3dTkj/v/z4L+r//LX2bz+pfiyng4n7dXfp9TG14fZL8SV/z55McNVLDy/t1lvTtuaH/OaYv493AL/bbPSvdDXsu7Pd9Y5IX9M9/TZJPJrkKuCbJfkmu6593S5Jf7Ld3JXDK5l4PPUEm/RVyf7bPH+AHwJ7AN4C9gDcB7+iXXQS8YnTd/vexwHeA/eiGRPgW8M5+2ZnA+0ae/1m6NzBL6YYW2Bk4Dfijfp0n0Q0rcXC/3R8CBzfq3J9uzJ5FdCOefgH41X7ZF+luNrOxNv5TO/p1P9Q/3hH4f8CifvqVwAX942XA0v7xz9GNBQVdcB3QP967//0C4PKR/b2j3+6TgH2AfwB23EhthwFXbVgOfAh4NfBc4HMj6+3dauvoNN1wLCf0jz8FXNO38Qjgpn7+rsDO/eOlwPTIa/qZke3+PnBh//jQ/m+/M90ZzFr64SD69d7WP14A7DGyja8BPzPpf+P+FLN5qqx5pqq+l+RjdHf1+vGYT1te/Rj2Sb5OdzCC7gD6gpH1Lq2qR4CvJVlDd7D5ZeBZI2cne9EdrB4CvlLdzVFm+jfAF6tqXb/Pi+lurPPpMesd9b/734cAzwQ+lwS6A9y96YZVPwb4ZD8fuoM9wN8AFyW5lG7UUeiCct2Mffx1VT0IPJjkPmBfugPrTMfRhcHyfl+70I3meRXw1CQfAP6af/77bspDdIEM3evwYFU9nGQl3SUk6ALjnCRHAj8Fnr6Rbf0C/SWzqro9yTdH1v1cVW246c1y4IJ0ow1/uqpuGtnGfXTB/g9j1K4BGRB6vN4H3ABcODJvPf3ly3RHr51Glj048viRkelHePS/x5mDhBXdOPdvqKqrRxckOZbuDKKlNTb+1tqwjwCrquroGXXsCXynuv6LR6mq05P8HN2d7m7qD7Q/pnt3PWr07/NTNv5/NMBHq+qtj1mQHAG8GDgD+PfAb226WTxc/Vt3Rl6TqnpkpL/gLODv6c4qdgB+som6NuafXqOqui7J8+n+Hh9P8p6q+li/eGfGf8OhAdkHocelf0d4KV2H7wbfoHt3C90NXXbcik2flGSHvl/iqXSjUl4N/G7/rpMkT09317RNuR74pST7pOvAPgX40lbUM+oOYFGSo/s6dkzyjOpuxnRnkpP6+ekP1iR5WlVdX1VvB+6nG6//NuBfbWUNy4BXJPnZfvtPSXJQug8N7FBVlwP/he6eEADfB/bYyn1Bd7Z2b39W9x/pzppa270O+I2+pqcD/5Lu7/UoSQ6iu7HTR+iGpH9OPz/Av6D7N6QJ8wxCs+G9wOtHpj8C/FWSr9AdyDb27n5T7qA7kO8LnF5VP0n3cdAlwA39gWQdm7nfcFXdm+StwLV0727/T1U9rvsDVNVD/WWu/5lkL7r/R+8DVtEdHD+c5I/ogvES4GbgPUmW9jUsA26uqkqyV5I9qrtn+JbUcGu/j2uS7EA3DPQZdO+8L+znAWw4w7iIrkP+x8DRM7c3hg8Bl/fhdy3//Jp+FVif5OZ+Hx/q97OS7kzyNVX14Mgltw2OBd6c5GG6/qxX9/OfC/xtVa3fiho1yxzuW5qgJGcB36+qwb8LsT1I8n7gyqpaNula5CUmadI+zKP7Hea7WwyHbYdnENI2LMmGu4bNdFxV+SkfDcqAkCQ1eYlJktRkQEiSmgwISVKTASFJavr/qY7B1rS3SbQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = []                            # records number of trees\n",
    "y_axis = []                            # records accuracy\n",
    "acc = 0                                # stores accuracy\n",
    "for i in range(1, 101):                # 1~100 trees\n",
    "    # build model\n",
    "    forest = RandomForestClassifier(criterion='gini', max_depth=1, n_estimators=i,\n",
    "                                    bootstrap=True, random_state=1, n_jobs=-1)                   \n",
    "    forest.fit(X_train_lda, y_train)\n",
    "    \n",
    "    x_axis.append(i)                          # put i into the list\n",
    "    acc = forest.score(X_test_lda, y_test)    # get accuracy\n",
    "    print('Accuracy when n = ', i, ':', acc)  # print accuracy & its num of trees\n",
    "    y_axis.append(acc)                        # put acc into the list\n",
    "\n",
    "# plot accuracy vs num of trees\n",
    "plt.plot(x_axis, y_axis)\n",
    "plt.xlabel('Number of Trees(n_estimators)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "發現將最大深度設為1後，它的performance反而沒有原本好。原本的model可能產生overfitting了。\n",
    "#### 1-6：比較training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time for SVM: 0:00:00.012963\n",
      "Accuracy for SVM: 0.9945848375451264\n",
      "Training time for Random Forest: 0:00:00.018949\n",
      "Accuracy for Random Forest: 0.8700361010830325\n",
      "Training time for Ensemble: 0:00:00.154587\n",
      "Accuracy for Ensemble: 0.983754512635379\n"
     ]
    }
   ],
   "source": [
    "# compare training time\n",
    "svm = SVC(C=1000.0, gamma=1000.0, kernel='rbf', random_state=1)\n",
    "start=datetime.now()                                 \n",
    "svm.fit(X_train_lda, y_train)\n",
    "print('Training time for SVM:', datetime.now()-start)\n",
    "print('Accuracy for SVM:', svm.score(X_test_lda, y_test))\n",
    "\n",
    "forest = RandomForestClassifier(criterion='gini', max_depth=1, n_estimators=2,\n",
    "                                    bootstrap=True, random_state=1, n_jobs=-1)\n",
    "start=datetime.now()                                 \n",
    "forest.fit(X_train_lda, y_train)\n",
    "print('Training time for Random Forest:', datetime.now()-start)\n",
    "print('Accuracy for Random Forest:', forest.score(X_test_lda, y_test))\n",
    "\n",
    "# ensemble\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=10, random_state=1)\n",
    "clf3 = KNeighborsClassifier()\n",
    "clf4 = SVC(probability=True)\n",
    "# larger weights for classifier w/ higher accuracy\n",
    "eclf = VotingClassifier(\n",
    "     estimators=[('lr', clf1), ('rf', clf2), ('knn', clf3), ('svm', clf4)],\n",
    "     voting='soft', weights=[1,4,4,1])\n",
    "start=datetime.now() \n",
    "eclf = eclf.fit(X_train_lda, y_train)\n",
    "print('Training time for Ensemble:', datetime.now()-start)\n",
    "print('Accuracy for Ensemble:', eclf.score(X_test_lda, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為SVM的訓練時間較短，又有好的performance，我們最終選擇使用SVM為我們的model。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 附錄：其他地區模型\n",
    "用1-3的方法訓練預測其他地區櫻花花期的模型。\n",
    "#### 京都\n",
    "讀進input data，並進行一連串data preprocessing。因為京都完全沒有全天日照量的資料，和東京相比、它原本的features數少1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1292, 1)\n",
      "(554, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.35318174],\n",
       "       [ 0.03894372],\n",
       "       [ 0.36811564],\n",
       "       [-0.25169177],\n",
       "       [ 0.18773929],\n",
       "       [-5.22561967],\n",
       "       [ 2.94779097],\n",
       "       [ 0.620679  ],\n",
       "       [ 1.3860487 ],\n",
       "       [-0.3099987 ],\n",
       "       [-0.37542344],\n",
       "       [-0.57379507],\n",
       "       [-0.41927516],\n",
       "       [ 0.59873984],\n",
       "       [-0.63222805],\n",
       "       [-0.02216921],\n",
       "       [ 0.36196838],\n",
       "       [-0.17313921],\n",
       "       [-0.01361691],\n",
       "       [ 0.03550258]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# read in data for prediction for Kyoto\n",
    "path = \"data_kyoto_pre.csv\"\n",
    "df = pd.read_csv(path, encoding='latin1')\n",
    "\n",
    "# put data into X & y\n",
    "data = df.T\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(data.T)): # for total input data\n",
    "    # store all data into X & y\n",
    "    X.append(np.array(data[i][3:23]))\n",
    "    y.append(data[i][23])\n",
    "\n",
    "# balance data\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "X_upsampled, y_upsampled = resample(X[y==1],\n",
    "                                   y[y==1],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X[y==0], X_upsampled))\n",
    "y_bal = np.hstack((y[y==0], y_upsampled))\n",
    "\n",
    "# split into 70% training & 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, \n",
    "        y_bal, test_size=0.3, random_state=1, stratify=y_bal)\n",
    "\n",
    "# standardize Xs\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "# feature-extract Xs\n",
    "lda = LDA(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train_std, y_train)\n",
    "X_test_lda = lda.transform(X_test_std)\n",
    "print(X_train_lda.shape)\n",
    "print(X_test_lda.shape)\n",
    "lda.scalings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了降過維度的input data後，利用Grid Search找合適的參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:13.032361\n",
      "0.9916256556534243\n",
      "{'C': 1000.0, 'gamma': 1000.0, 'kernel': 'rbf'}\n",
      "accuracy: 0.9909747292418772\n",
      "f1 score: 0.9910554561717353\n",
      "f1 score macro: 0.9909739940239368\n",
      "f1 score micro: 0.9909747292418772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# train SVM using Grid Search\n",
    "svm = SVC(random_state=1)\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'C': param_range,\n",
    "               'kernel':['linear']},\n",
    "              {'C': param_range,\n",
    "               'gamma': param_range,\n",
    "               'kernel': ['rbf']}]\n",
    "gs = GridSearchCV(estimator=svm,\n",
    "                 param_grid = param_grid,\n",
    "                 scoring='f1',\n",
    "                 refit=True,\n",
    "                 cv=10,\n",
    "                 n_jobs=-1)\n",
    "start=datetime.now()\n",
    "gs = gs.fit(X_train_lda, y_train)\n",
    "print('Training time:', datetime.now()-start)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "y_pred = clf.predict(X_test_lda)\n",
    "print (\"accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print (\"f1 score:\",metrics.f1_score(y_test, y_pred) )\n",
    "print (\"f1 score macro:\",metrics.f1_score(y_test, y_pred, average='macro') )\n",
    "print (\"f1 score micro:\",metrics.f1_score(y_test, y_pred, average='micro') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到與東京的資料相比，京都的準確率要再低一些，約99.1%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後畫出consusion matrix。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1de5b8ded00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf, X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從confusion matrix可以看出來，雖然這個model會有誤判的時候，但卻不會錯過任何\"下半旬\"開花的可能性，且預測會開花、而真的有開花的機率挺高的，約為98.2%（=277/(277+5)）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 函館\n",
    "讀進input data，並進行一連串data preprocessing。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1292, 1)\n",
      "(554, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.17742807],\n",
       "       [-0.00894984],\n",
       "       [ 0.38458295],\n",
       "       [-0.09998159],\n",
       "       [-0.08707423],\n",
       "       [ 3.96302374],\n",
       "       [-2.96997558],\n",
       "       [-3.57366288],\n",
       "       [ 0.15263918],\n",
       "       [ 1.03428125],\n",
       "       [ 0.2671861 ],\n",
       "       [-0.73523271],\n",
       "       [-0.46944411],\n",
       "       [ 1.20433658],\n",
       "       [ 0.11829928],\n",
       "       [-0.20451166],\n",
       "       [-0.39577741],\n",
       "       [ 0.41661218],\n",
       "       [-0.90885979],\n",
       "       [-0.01331803],\n",
       "       [ 0.05556194]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "# read in data for prediction for Hakodate\n",
    "path = \"data_hakodate_pre.csv\"\n",
    "df = pd.read_csv(path, encoding='latin1')\n",
    "\n",
    "# put data into X & y\n",
    "data = df.T\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(data.T)): # for total input data\n",
    "    # store all data into X & y\n",
    "    X.append(np.array(data[i][3:24]))\n",
    "    y.append(data[i][24])\n",
    "\n",
    "# balance data\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "X_upsampled, y_upsampled = resample(X[y==1],\n",
    "                                   y[y==1],\n",
    "                                   replace=True,\n",
    "                                   n_samples=X[y==0].shape[0],\n",
    "                                   random_state=123)\n",
    "X_bal = np.vstack((X[y==0], X_upsampled))\n",
    "y_bal = np.hstack((y[y==0], y_upsampled))\n",
    "\n",
    "# split into 70% training & 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, \n",
    "        y_bal, test_size=0.3, random_state=1, stratify=y_bal)\n",
    "\n",
    "# standardize Xs\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "\n",
    "# feature-extract Xs\n",
    "lda = LDA(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train_std, y_train)\n",
    "X_test_lda = lda.transform(X_test_std)\n",
    "print(X_train_lda.shape)\n",
    "print(X_test_lda.shape)\n",
    "lda.scalings_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了降過維度的input data後，利用Grid Search找合適的參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:21.270842\n",
      "0.9863385827703619\n",
      "{'C': 100.0, 'gamma': 1000.0, 'kernel': 'rbf'}\n",
      "accuracy: 0.9891696750902527\n",
      "f1 score: 0.9892857142857143\n",
      "f1 score macro: 0.9891684045881126\n",
      "f1 score micro: 0.9891696750902527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "\n",
    "# train SVM using Grid Search\n",
    "svm = SVC(random_state=1)\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "param_grid = [{'C': param_range,\n",
    "               'kernel':['linear']},\n",
    "              {'C': param_range,\n",
    "               'gamma': param_range,\n",
    "               'kernel': ['rbf']}]\n",
    "gs = GridSearchCV(estimator=svm,\n",
    "                 param_grid = param_grid,\n",
    "                 scoring='f1',\n",
    "                 refit=True,\n",
    "                 cv=10,\n",
    "                 n_jobs=-1)\n",
    "start=datetime.now()\n",
    "gs = gs.fit(X_train_lda, y_train)\n",
    "print('Training time:', datetime.now()-start)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "y_pred = clf.predict(X_test_lda)\n",
    "print (\"accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print (\"f1 score:\",metrics.f1_score(y_test, y_pred) )\n",
    "print (\"f1 score macro:\",metrics.f1_score(y_test, y_pred, average='macro') )\n",
    "print (\"f1 score micro:\",metrics.f1_score(y_test, y_pred, average='micro') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到與東京和京都的資料相比，函館的準確率要再低一些，約98.9%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後畫出consusion matrix。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1de5ab250a0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "plot_confusion_matrix(clf, X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和前述模型相同，雖然這個model也會有誤判的時候，但卻不會錯過任何\"下半旬\"開花的可能性，且預測會開花、而真的有開花的機率挺高的，約為97.9%（=277/(277+6)）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2Z1hvAAb2nS"
   },
   "source": [
    "### References\n",
    "* 機器學習講義與筆記\n",
    "* python 相關教學網頁"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW5_106061140.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
